(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[291],{9066:function(e,n,t){(window.__NEXT_P=window.__NEXT_P||[]).push(["/usage",function(){return t(5276)}])},5276:function(e,n,t){"use strict";t.r(n),t.d(n,{default:function(){return d}});var a=t(5893),r=(t(7294),t(4858)),i=t(7418),o=t(104),s=t(2324);function l(){s.w(1,3).forEach((function(e){window.open("/utsd/data/zips/UTSD.7z.00".concat(e),"_blank")}))}function d(){return(0,a.jsxs)(o.Z,{children:[(0,a.jsxs)(r.kd,{children:["The simplest way to get started is to"," ",(0,a.jsx)(i.Z,{href:"#",text:"download the entire UTSD collection",onClick:l})," (the download is split into two files). Optionally, you can download individual tasks by"," ",(0,a.jsx)(i.Z,{href:"/",text:"selecting the task in the overview table and clicking download"}),". The data for each task is provided in multiple CSV files. There is one file containing all datapoints considered normal and ten files containing randomly sampled outliers. The files are named"," ",(0,a.jsx)("i",{children:"$(DATASET)_$(CLASSES)_$(FRACTION)_$(VARIANT).csv"}),", for example, ",(0,a.jsx)("i",{children:"Crop_1_0.1_1.csv"})," would describe the first randomly sampled variant of the 'Crop' dataset with with 10% outliers and one normal class."]}),(0,a.jsxs)(r.kd,{children:["The following example shows how to predict a single variant of the previously mentioned task using Python and the ",(0,a.jsx)(i.Z,{href:"https://scikit-learn.org/stable/",text:"scikit-learn library"}),"."]}),(0,a.jsx)("pre",{style:{overflowX:"auto"},children:(0,a.jsx)("code",{children:'\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.metrics import roc_auc_score\n\ndef cross_validate(model, x, y, n_splits=2, n_repeats=5, random_state=0):\n    """\n    Calculates the mean stratified cv result over a number of folds and repeats.\n    Note: The model is expected to follow the scikit-learn outlier detection\n    interface providing `fit` and `decision_function` methods. Additionally,\n    scikit-learn models use increasing scores to indicate normality.\n    """\n    cv = RepeatedStratifiedKFold(\n        n_splits=n_splits,\n        n_repeats=n_repeats,\n        random_state=random_state\n    )\n    results = []\n    for train_index, test_index in cv.split(x, y):\n        model.fit(x[train_index])\n        y_true = y[test_index]\n        y_pred = model.decision_function(x[test_index])\n        score = roc_auc_score(y_true, -y_pred)\n        results.append(score)\n    return np.mean(results)\n\nmodel = IsolationForest(random_state=0)\ndataset = "Crop"\nclasses = 1\nfraction = 0.1\nvariant = 1\n\n# read normal data\nx_normal = pd.read_csv(PATH_TO_DATASETS / dataset / f"{dataset}_{classes}_normal.csv", header=None)\ny_normal = np.zeros(len(x_normal))\n\n# read outlier data\nx_outlier = pd.read_csv(PATH_TO_DATASETS / dataset / f"{dataset}_{classes}_{fraction}_{variant}.csv", header=None)\ny_outlier = np.ones(len(x_outlier))\n\n# concatenate data\nx = np.concatenate([x_normal, x_outlier])\ny = np.concatenate([y_normal, y_outlier])\n\n# predict roc auc\ncross_validate(model, x, y)\n'})}),(0,a.jsxs)(r.kd,{children:["Similarly, predicting a single variant with Julia using"," ",(0,a.jsx)(i.Z,{href:"https://alan-turing-institute.github.io/MLJ.jl/dev/",text:"MLJ"})," and"," ",(0,a.jsx)(i.Z,{href:"https://outlierdetectionjl.github.io/OutlierDetection.jl/stable/",text:"OutlierDetection.jl"})," ","can be achieved as follows."]}),(0,a.jsx)("pre",{style:{overflowX:"auto"},children:(0,a.jsx)("code",{children:'\nusing CSV\nusing MLJ\nusing OutlierDetection\nusing DataFrames\nKNN = @iload KNNDetector pkg = OutlierDetectionNeighbors\n\nfunction cross_validate(model, x, y, n_splits=2, n_repeats=5, random_state=0)\n    """\n    Calculates the mean stratified cv result over a number of folds and repeats.\n    """\n    cv = StratifiedCV(nfolds=n_splits, shuffle=true, rng=random_state)\n    probabilistic_model = ProbabilisticDetector(model)\n    score = evaluate(probabilistic_model, x, y;\n        resampling=cv,\n        repeats=n_repeats\n    ).measurement[1]\n    return score\nend\n\nmodel = KNN(k=100)\ndataset = "Crop"\nclasses = 1\nfraction = 0.1\nvariant = 1\n\n# read normal data\nx_normal = CSV.read("$(PATH_TO_DATASETS)/$(dataset)/$(dataset)_$(classes)_normal.csv", DataFrame, header=false)\ny_normal = repeat(["normal"], nrow(x_normal))\n\n# read outlier data\nx_outlier = CSV.read("$(PATH_TO_DATASETS)/$(dataset)/$(dataset)_$(classes)_$(fraction)_$(variant).csv", DataFrame, header=false)\ny_outlier = repeat(["outlier"], nrow(x_outlier))\n\n# concatenate data\nx = reduce(vcat, [x_normal, x_outlier])\ny = vcat(y_normal, y_outlier) |> to_categorical\n\n# predict roc auc\ncross_validate(model, x, y)\n'})}),(0,a.jsxs)(r.kd,{children:["Using a different programming language?"," ",(0,a.jsx)(i.Z,{href:"https://github.com/outlier-detection/utsd/issues/new",text:"Help us improve the documentation by providing a similar code snippet"}),"."]})]})}},9782:function(e,n,t){"use strict";t.d(n,{$:function(){return r}});var a=function(e,n,t){if(t||2===arguments.length)for(var a,r=0,i=n.length;r<i;r++)!a&&r in n||(a||(a=Array.prototype.slice.call(n,0,r)),a[r]=n[r]);return e.concat(a||Array.prototype.slice.call(n))};function r(e,n,t){var r=e.length-n.length,i=Array.from(n);if(0===r)return e.apply(void 0,i);if(1===r){var o=function(n){return e.apply(void 0,a([n],i,!1))};return(t||e.lazy)&&(o.lazy=t||e.lazy,o.lazyArgs=n),o}throw new Error("Wrong number of arguments")}},2324:function(e,n,t){"use strict";t.d(n,{w:function(){return r}});var a=t(9782);function r(){return(0,a.$)(i,arguments)}function i(e,n){for(var t=[],a=e;a<n;a++)t.push(a);return t}}},function(e){e.O(0,[774,888,179],(function(){return n=9066,e(e.s=n);var n}));var n=e.O();_N_E=n}]);